{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow2.0 小练习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现softmax函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7522302  -0.05871538 -0.3995748   1.4157422  -0.05660807]\n",
      " [-0.20385897  1.3567791   0.19437975 -0.04637642  0.13372248]\n",
      " [-0.016101   -0.57322943  2.3795023  -0.8478688  -0.70687836]\n",
      " [ 1.9659184   1.6274889  -0.2850514   1.556407   -0.74753094]\n",
      " [ 0.5989454  -1.785647    1.4455488  -0.95527136 -1.2994574 ]\n",
      " [ 0.7322035  -0.5830047   1.963724   -0.9338021  -0.4387086 ]\n",
      " [ 0.05598401  0.5450637  -0.9637479  -0.12449894 -0.41151586]\n",
      " [ 1.0257028   0.89750886 -0.8318968  -1.5604948  -0.1657166 ]\n",
      " [ 1.1550524  -1.385352    0.7867837  -0.3040725   1.0288265 ]\n",
      " [ 1.1559253  -1.4780195   0.2581899   0.36149567 -1.1963102 ]]\n",
      "[[0.2411104  0.10715853 0.07620674 0.46813974 0.10738458]\n",
      " [0.10180011 0.4847577  0.15160067 0.11916316 0.14267832]\n",
      " [0.07416123 0.04248339 0.81390595 0.03228084 0.03716859]\n",
      " [0.3923926  0.27973235 0.04131778 0.2605387  0.02601865]\n",
      " [0.2642006  0.02433988 0.6160401  0.05584009 0.03957928]\n",
      " [0.1925321  0.05167916 0.6596989  0.03638867 0.05970113]\n",
      " [0.22457077 0.36623326 0.08100078 0.18748668 0.14070858]\n",
      " [0.4141087  0.36428428 0.06462032 0.0311848  0.12580198]\n",
      " [0.346666   0.02732925 0.23986904 0.08057891 0.30555683]\n",
      " [0.49351493 0.03543175 0.2011031  0.22298923 0.04696101]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    ##########\n",
    "    '''实现softmax函数，只要求对最后一维归一化，\n",
    "    不允许用tf自带的softmax函数'''\n",
    "    ##########\n",
    "\n",
    "    # 将输入转换为TensorFlow张量，确保数据类型为float32\n",
    "    x = tf.cast(x, tf.float32)\n",
    "\n",
    "    # 计算指数\n",
    "    exp_x = tf.exp(x)\n",
    "\n",
    "    # 计算最后一维的指数和，用于归一化\n",
    "    # 最后一维通常是属于某个类别的概率，对其进行归一化\n",
    "    sum_exp_x = tf.reduce_sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "    # 计算softmax概率：每个元素的指数值除以指数和\n",
    "    prob_x = exp_x / sum_exp_x\n",
    "\n",
    "    return prob_x\n",
    "\n",
    "#测试数据，来自随机正态分布\n",
    "test_data = np.random.normal(size=[10, 5]).astype(np.float32)\n",
    "print(test_data)\n",
    "print(softmax(test_data).numpy())\n",
    "#比较softmax函数的结果是否与tf.nn.softmax函数的结果一致\n",
    "(softmax(test_data).numpy() - tf.nn.softmax(test_data, axis=-1).numpy())**2 <0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现sigmoid函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    ##########\n",
    "    '''实现sigmoid函数， 不允许用tf自带的sigmoid函数'''\n",
    "    ##########\n",
    "    \n",
    "    # 将输入转换为TensorFlow张量，确保数据类型为float32\n",
    "    x = tf.cast(x, tf.float32)\n",
    "\n",
    "    #sigmoid(x) = 1 / (1 + exp(-x))\n",
    "    prob_x = 1.0 / (1.0 + tf.exp(-x))\n",
    "\n",
    "    return prob_x\n",
    "\n",
    "test_data = np.random.normal(size=[10, 5])\n",
    "(sigmoid(test_data).numpy() - tf.nn.sigmoid(test_data).numpy())**2 < 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现 softmax 交叉熵loss函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax_ce(x, label):\n",
    "    ##########\n",
    "    '''实现 softmax 交叉熵loss函数， 不允许用tf自带的softmax_cross_entropy函数'''\n",
    "    ##########\n",
    "    \n",
    "    # x 为概率分布（已 softmax），label 为 one-hot 或概率标签\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    # 交叉熵： -sum(label * log(x))\n",
    "    #ce_per_example 为每个样本的交叉熵损失\n",
    "    ce_per_example = -tf.reduce_sum(label * tf.math.log(x), axis=-1)\n",
    "    # 对每个样本的交叉熵损失取均值，得到 batch 平均损失\n",
    "    loss = tf.reduce_mean(ce_per_example)\n",
    "\n",
    "    return loss\n",
    "\n",
    "test_data = np.random.normal(size=[10, 5]).astype(np.float32)\n",
    "prob = tf.nn.softmax(test_data)\n",
    "# 生成 one-hot 标签\n",
    "label = np.zeros_like(test_data, dtype=np.float32)\n",
    "label[np.arange(10), np.random.randint(0, 5, size=10)] = 1.0\n",
    "\n",
    "((tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(label, test_data))\n",
    "  - softmax_ce(prob, label))**2 < 0.0001).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现 sigmoid 交叉熵loss函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 1. 1. 0. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid_ce(x, label):\n",
    "    ##########\n",
    "    '''实现 sigmoid 交叉熵loss函数， 不允许用tf自带的sigmoid_cross_entropy函数'''\n",
    "    ##########\n",
    "    # x 为概率 ŷ ∈ (0,1)，label ∈ [0,1]（可为0/1或概率）\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    # 概率版二元交叉熵：L = -[ y*log(ŷ) + (1-y)*log(1-ŷ) ]\n",
    "    ce = -(label * tf.math.log(x) + (1.0 - label) * tf.math.log(1.0 - x))\n",
    "\n",
    "    # 若最后一维为类别维（多标签），按最后一维求和得到每样本损失；否则直接视为每样本损失\n",
    "    ce_per_example = tf.reduce_sum(ce, axis=-1) if len(ce.shape) > 1 else ce\n",
    "\n",
    "    # 对 batch 取均值，得到标量损失\n",
    "    loss = tf.reduce_mean(ce_per_example)\n",
    "    return loss\n",
    "\n",
    "test_data = np.random.normal(size=[10]).astype(np.float32)\n",
    "prob = tf.nn.sigmoid(test_data)\n",
    "label = np.random.randint(0, 2, 10).astype(np.float32)\n",
    "print (label)\n",
    "\n",
    "((tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(label, test_data)) - sigmoid_ce(prob, label))**2 < 0.0001).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
